"""
Response Generator Agent: ìµœì¢… ì‘ë‹µ ìƒì„± ì—ì´ì „íŠ¸ (Powered by Gemini)
"""
import logging
from typing import Dict, Any, List
from datetime import datetime

import os
try:
    # Optional LLM binding (only loaded when ENABLE_LLM=1)
    from langchain_google_genai import ChatGoogleGenerativeAI
except Exception:
    ChatGoogleGenerativeAI = None


logger = logging.getLogger(__name__)

class ResponseGeneratorAgent:
    def __init__(self):
        # LLM initialization is optional and gated by environment to keep tests
        # and CI lightweight. Set ENABLE_LLM=1 to attempt to use Google Gemini.
        self.llm = None
        self.enable_llm = os.getenv('ENABLE_LLM', '').lower() in ('1', 'true', 'yes') and ChatGoogleGenerativeAI is not None
        if self.enable_llm:
            try:
                self.llm = ChatGoogleGenerativeAI(model="gemini-2.5-pro", temperature=0.7)
            except Exception:
                self.llm = None

        # Use a simple string template for prompt formatting to avoid hard
        # dependency on langchain prompt classes in tests.
        self.prompt_template = (
            "ë‹¹ì‹ ì€ ê°ê°ì ì´ê³  ì „ë¬¸ì ì¸ ì—¬í–‰ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ê°€ë…ì„± ë†’ê³  ë§¤ë ¥ì ì¸ ì—¬í–‰ ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
            
            "**[ì§€ì¹¨]**\n"
            "1. **í†¤ì•¤ë§¤ë„ˆ**: ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì´ë©°, ì—¬í–‰ì˜ ì„¤ë ˜ì´ ëŠê»´ì§€ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.\n"
            "2. **ê°€ë…ì„±(Formatting)**: \n"
            "   - ëª¨ë“  ì„¹ì…˜ ì œëª©(Header) ì•ì—ëŠ” ë°˜ë“œì‹œ ê´€ë ¨ëœ **ì´ëª¨ì§€**ë¥¼ ë¶™ì´ì„¸ìš”. (ì˜ˆ: ## âœˆï¸ í•­ê³µí¸, ## ğŸ¨ ìˆ™ì†Œ)\n"
            "   - ì¤‘ìš” ì •ë³´ëŠ” **ë³¼ë“œì²´**ë¡œ ê°•ì¡°í•˜ì„¸ìš”.\n"
            "   - ì¼ì°¨ë³„ ì¼ì •ì€ íƒ€ì„ë¼ì¸ í˜•íƒœë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(Bullet points)ë¥¼ ì‚¬ìš©í•´ ì •ë¦¬í•˜ì„¸ìš”.\n"
            "3. **ì´ëª¨ì§€ ì‚¬ìš© ì›ì¹™**: ë¬¸ë§¥ì— ê°€ì¥ ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ë‹¹ì‹ ì´ ììœ ë¡­ê²Œ ì„ íƒí•˜ë˜, ê³¼í•˜ì§€ ì•Šê²Œ ì ì¬ì ì†Œì— ë°°ì¹˜í•˜ì„¸ìš”.\n"
            "4. **ë‚ ì”¨ ì •ë³´ ì²˜ë¦¬**: ë‚ ì”¨ ì˜ˆë³´ê°€ Markdown í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ë©´ **ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì„¸ìš”. í…Œì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì§€ ë§ˆì„¸ìš”.\n\n"

            "**[ì‘ì„± í¬ë§· ì˜ˆì‹œ]**\n"
            "## ğŸŒ¤ï¸ ë‚ ì”¨ ì˜ˆë³´\n"
            "| ë‚ ì§œ | ë‚ ì”¨ | ìµœì €ê¸°ì˜¨ | ìµœê³ ê¸°ì˜¨ | ê°•ìˆ˜ëŸ‰ |\n"
            "|------|------|----------|----------|--------|\n"
            "| 2025-12-01 | ì•½í•œ ë¹„ | 4.5Â°C | 9.1Â°C | 4.1mm |\n\n"
            "## ğŸ¨ ì¶”ì²œ ìˆ™ì†Œ\n"
            "### í˜¸í…”ëª…\n"
            "- í‰ì : â­ 4.5\n"
            "- **ê°€ê²©**: 1ë°• ì•½ $250 (ì‹¤ì‹œê°„) ë˜ëŠ” $$-$$$\n"
            "- ğŸ” [êµ¬ê¸€ì—ì„œ ê²€ìƒ‰](https://www.google.com/search?q=í˜¸í…”ëª…)\n\n"
            "### ğŸ“… 1ì¼ì°¨: [í…Œë§ˆ]\n"
            "- **ì˜¤ì „ (09:00)**: ğŸ›ï¸ [ì¥ì†Œëª…] ë°©ë¬¸\n"
            "- **ì ì‹¬**: ğŸ½ï¸ [ì‹ë‹¹ëª…]ì—ì„œ í˜„ì§€ì‹ ì¦ê¸°ê¸°\n\n"
            
            "**[ì…ë ¥ ë°ì´í„°]**\n"
            "- ëª©ì ì§€: {destination}\n"
            "- ì—¬í–‰ ë‚ ì§œ: {dates}\n"
            "- ì—¬í–‰ ì¸ì›: {traveler_count}ëª…\n"
            "- ì„ í˜¸ì‚¬í•­: {preferences}\n"
            "- í˜¸í…” ì •ë³´: {hotel_results}\n"
            "- ë‚ ì”¨ ì˜ˆë³´: {weather_forecast}\n"
            "- ê²€ìƒ‰ ì •ë³´: {google_info}\n"
            "- í™˜ìœ¨ ì •ë³´: {currency_info}\n"
            "- ìœ„í‚¤ë°±ê³¼ ì •ë³´: {wiki_snippets}\n\n"
            
            "**[ì¤‘ìš”]** ë‚ ì”¨ ì˜ˆë³´ê°€ í…Œì´ë¸” í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”. ì ˆëŒ€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "**[í™˜ìœ¨ ì •ë³´]** ì œê³µëœ í™˜ìœ¨ ì •ë³´(ê¸°ë³¸ í†µí™”: USD)ë¥¼ ì°¸ê³ í•˜ì—¬ ìˆ™ë°•ë£Œ, ìŒì‹ê°’, ì•¡í‹°ë¹„í‹° ê°€ê²© ë“±ì„ ë‹¤ì–‘í•œ í†µí™”ë¡œ í‘œì‹œí•˜ë©´ ì‚¬ìš©ìê°€ ì˜ˆì‚°ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "**[ìœ„í‚¤ë°±ê³¼]** ì œê³µëœ ìœ„í‚¤ë°±ê³¼ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì—¬í–‰ì§€ì˜ ì—­ì‚¬, ë¬¸í™”ì  ë°°ê²½, ëª…ì†Œì˜ ìœ ë˜ ë“±ì„ ì¼ì • ì„¤ëª…ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”.\n\n"
            "**í˜¸í…” ê°€ê²© ì •ë³´ëŠ” ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.** ì‹¤ì‹œê°„ ê°€ê²©ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„, ì—†ìœ¼ë©´ ì˜ˆì‚° ë²”ìœ„($ í‘œì‹œ)ë¥¼ í‘œê¸°í•˜ì„¸ìš”.\n"
            "ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬í–‰ìê°€ ë°”ë¡œ ë– ë‚˜ê³  ì‹¶ì–´ì§€ë„ë¡ ìƒì„¸í•œ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
        logger.info("ResponseGeneratorAgent(Gemini) ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def generate(self, state: Dict[str, Any]) -> Dict[str, Any]:
        try:
            destination = state.get('destination', 'ëª©ì ì§€ ë¯¸ì •')
            dates = state.get('travel_dates', ['ë‚ ì§œ ë¯¸ì •'])
            
            # ë‚ ì”¨ ì •ë³´ í¬ë§·íŒ…
            weather_info = self._format_weather_forecast(
                state.get('weather_forecast', []),
                state.get('context_memory', {}).get('weather_limitation_message')
            )
            
            prompt_text = self.prompt_template.format(
                destination=destination,
                dates=' ~ '.join(dates) if isinstance(dates, list) else dates,
                traveler_count=state.get('traveler_count', 1),
                preferences=str(state.get('preferences', {})),
                hotel_results=self._format_hotel_results(state.get('hotel_options', [])),
                weather_forecast=weather_info,
                google_info=str(state.get('google_search_results', [])),
                currency_info=self._format_currency_info(state.get('context', {}).get('currency_conversions', {})),
                wiki_snippets=self._format_wiki_entries(state.get('wiki_entries', []))
            )

            if self.llm:
                try:
                    response = await self.llm.ainvoke(prompt_text)
                    content = getattr(response, 'content', str(response))
                except Exception:
                    content = "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                # Lightweight fallback summary (non-LLM)
                content = f"{destination}ì— ëŒ€í•œ ê°„ë‹¨í•œ ì¼ì •ì…ë‹ˆë‹¤. í˜¸í…” {len(state.get('hotel_options', []))}ê³³ ì¶”ì²œ." 

            return {
                'destination': destination,
                'dates': dates,
                'summary': content,
                'hotels': [{'name': h.name, 'rating': h.rating, 'price': h.price_range, 'highlights': h.review_highlights} for h in state.get('hotel_options', [])[:3]],
                'generated_at': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'summary': f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", 'hotels': []}

    def _format_hotel_results(self, hotels: List) -> str:
        """í˜¸í…” ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ… (êµ¬ê¸€ ê²€ìƒ‰ URL í¬í•¨)"""
        if not hotels:
            return "ê²€ìƒ‰ëœ í˜¸í…” ì—†ìŒ"
        
        import urllib.parse
        
        formatted_hotels = []
        for h in hotels[:3]:
            # êµ¬ê¸€ ê²€ìƒ‰ URL ìƒì„±
            search_query = f"{h.name} hotel"
            google_url = f"https://www.google.com/search?q={urllib.parse.quote(search_query)}"
            
            # í˜¸í…” ì •ë³´ + URL
            formatted_hotels.append(
                f"- {h.name} (í‰ì : {h.rating}, ê°€ê²©: {h.price_range})\n"
                f"  ğŸ” [êµ¬ê¸€ì—ì„œ ê²€ìƒ‰]({google_url})"
            )
        
        return "\n".join(formatted_hotels)
    
    def _format_weather_forecast(self, forecasts: List, limitation_message: str = None) -> str:
        """
        ë‚ ì”¨ ì˜ˆë³´ë¥¼ Markdown í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        """
        if not forecasts:
            if limitation_message:
                return f"âš ï¸ {limitation_message}"
            return "ë‚ ì”¨ ì •ë³´ ì—†ìŒ (ë‚ ì§œê°€ 2ì£¼ ì´í›„ì´ê±°ë‚˜ ì¡°íšŒ ì‹¤íŒ¨)"
        
        table = "| ë‚ ì§œ | ë‚ ì”¨ | ìµœì €ê¸°ì˜¨ | ìµœê³ ê¸°ì˜¨ | ê°•ìˆ˜ëŸ‰ |\n"
        table += "|------|------|----------|----------|--------|\n"
        
        for forecast in forecasts:
            table += f"| {forecast.date} | {forecast.description} | {forecast.temperature_min}Â°C | {forecast.temperature_max}Â°C | {forecast.precipitation}mm |\n"
        
        return table
    
    def _format_currency_info(self, currency_data: Dict) -> str:
        """í™˜ìœ¨ ì •ë³´ë¥¼ í¬ë§·íŒ…"""
        if not currency_data:
            return "í™˜ìœ¨ ì •ë³´ ì—†ìŒ"
        
        base_currency = currency_data.get('base_currency', 'USD')
        exchange_rates = currency_data.get('exchange_rates', {})
        
        if not exchange_rates:
            return f"ê¸°ë³¸ í†µí™”: {base_currency}"
        
        # ì£¼ìš” í†µí™”ë§Œ í‘œì‹œ (ìµœëŒ€ 5ê°œ)
        major_currencies = ['EUR', 'GBP', 'JPY', 'KRW', 'CNY']
        rates_text = f"**ê¸°ë³¸ í†µí™”: {base_currency}**\n"
        rates_text += "í™˜ìœ¨:\n"
        
        displayed_count = 0
        for curr in major_currencies:
            if curr in exchange_rates and displayed_count < 5:
                rates_text += f"- {curr}: {exchange_rates[curr]:.2f}\n"
                displayed_count += 1
        
        return rates_text
    
    def _format_wiki_entries(self, wiki_entries: List[Dict]) -> str:
        """Format wiki entries (title, summary, source) into readable text."""
        if not wiki_entries:
            return "ìœ„í‚¤ë°±ê³¼ ì •ë³´ ì—†ìŒ"
        
        formatted = []
        for entry in wiki_entries:
            if isinstance(entry, dict):
                if entry.get('error'):
                    # Skip error entries
                    continue
                title = entry.get('title', 'Unknown')
                summary = entry.get('summary', '')
                source = entry.get('source', '')
                
                text = f"**{title}**: {summary}"
                if source:
                    text += f" ([ì¶œì²˜]({source}))"
                formatted.append(text)
        
        return "\n\n".join(formatted) if formatted else "ìœ„í‚¤ë°±ê³¼ ì •ë³´ ì—†ìŒ"

    async def stream_response(self, state: Dict[str, Any]):
        """Async generator that yields parts of the response incrementally.

        This is a lightweight PoC for streaming responses without invoking the
        LLM for every partial update. It yields three steps:
        1) hotels list
        2) weather table or message
        3) final summary (placeholder if LLM not available)
        """
        # 1) hotels
        hotels = [{'name': h.name, 'rating': h.rating, 'price': h.price_range, 'highlights': h.review_highlights} for h in state.get('hotel_options', [])[:3]]
        yield {'step': 'hotels', 'hotels': hotels}

        # 2) weather
        weather_info = self._format_weather_forecast(
            state.get('weather_forecast', []),
            state.get('context_memory', {}).get('weather_limitation_message')
        )
        yield {'step': 'weather', 'weather': weather_info}

        # 3) final summary â€” try LLM generate, but fall back to a simple placeholder
        try:
            final = await self.generate(state)
            yield {'step': 'final', 'itinerary': final}
        except Exception:
            # Non-fatal fallback
            yield {'step': 'final', 'itinerary': {'summary': 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'}}
