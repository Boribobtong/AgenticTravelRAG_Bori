"""
ElasticSearch ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸ (ë©”íƒ€ë°ì´í„° ë³´ê°• ë²„ì „)

ë¬¸ì œ í•´ê²°: ì›ë³¸ ë°ì´í„°ì— í˜¸í…” ìœ„ì¹˜/ì´ë¦„ì´ ì—†ìœ¼ë¯€ë¡œ, 
ê° hotel_idì— ëœë¤í•˜ê²Œ ì¸ê¸° ë„ì‹œì™€ ê°€ìƒì˜ í˜¸í…” ì´ë¦„ì„ ë¶€ì—¬í•˜ì—¬ ì¸ë±ì‹±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python -m data.scripts.index_to_elastic
    ë˜ëŠ”
    python data/scripts/index_to_elastic.py
"""

import os
import json
import random
import requests
from pathlib import Path
from loguru import logger
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python Pathì— ì¶”ê°€
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.rag.elasticsearch_rag import get_rag_instance, ReviewDocument

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv("config/.env")

DATA_DIR = Path("data/raw")
INPUT_FILE = DATA_DIR / "tripadvisor_reviews.jsonl"

# ==========================================
# ğŸŒ ê°€ìƒ ë©”íƒ€ë°ì´í„° ìƒì„±ê¸°
# ==========================================
CITIES = ["Paris", "New York", "Seoul", "Bangkok", "London", "Tokyo", "Barcelona", "Rome"]
HOTEL_TYPES = ["Grand Hotel", "Resort & Spa", "Boutique Stay", "Guesthouse", "Plaza", "Inn"]
ADJECTIVES = ["Luxury", "Cozy", "Modern", "Historic", "Royal", "City"]

class MetadataGenerator:
    def __init__(self):
        self.hotel_map = {}  # hotel_id -> (name, location) ë§¤í•‘

    def get_metadata(self, hotel_id: int):
        """í˜¸í…” IDë³„ë¡œ ì¼ê´€ëœ ê°€ìƒ ì´ë¦„/ìœ„ì¹˜ ë°˜í™˜"""
        if hotel_id not in self.hotel_map:
            city = random.choice(CITIES)
            name = f"{random.choice(ADJECTIVES)} {city} {random.choice(HOTEL_TYPES)}"
            self.hotel_map[hotel_id] = {"name": name, "location": city}
        return self.hotel_map[hotel_id]

# ==========================================

def check_elasticsearch_connection():
    """ElasticSearch ì—°ê²° ìƒíƒœ í™•ì¸"""
    es_host = os.getenv("ES_HOST", "localhost")
    es_port = os.getenv("ES_PORT", "9200")
    es_url = f"http://{es_host}:{es_port}"
    
    try:
        response = requests.get(es_url, timeout=5)
        if response.status_code == 200:
            return True, es_url
        return False, es_url
    except requests.exceptions.RequestException:
        return False, es_url

def load_raw_data():
    if not INPUT_FILE.exists():
        logger.error(f"ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {INPUT_FILE}")
        return []
    
    data = []
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data.append(json.loads(line))
            except:
                continue
    return data

def index_data():
    print("\n" + "="*60)
    print("ğŸ“Š ElasticSearch ì¸ë±ì‹± ì‹œì‘")
    print("="*60 + "\n")
    
    # ElasticSearch ì—°ê²° í™•ì¸
    print("ğŸ” ElasticSearch ì—°ê²° í™•ì¸ ì¤‘...")
    is_connected, es_url = check_elasticsearch_connection()
    
    if not is_connected:
        print(f"âŒ ElasticSearchì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {es_url}")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ElasticSearchë¥¼ ì‹œì‘í•˜ì„¸ìš”:")
        print("  docker-compose -f docker/docker-compose.yml up -d elasticsearch")
        print("\nì—°ê²° í™•ì¸:")
        print(f"  curl {es_url}\n")
        print("="*60 + "\n")
        return
    
    print(f"âœ… ElasticSearch ì—°ê²° ì„±ê³µ: {es_url}\n")
    
    logger.info("ë°ì´í„° ì¸ë±ì‹± ì‹œì‘ (ë©”íƒ€ë°ì´í„° ë³´ê°• í¬í•¨)...")
    
    rag = get_rag_instance()
    print("ğŸ—‘ï¸  ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ë° ì¬ìƒì„± ì¤‘...")
    rag.create_index(force_recreate=True)
    
    raw_data = load_raw_data()
    if not raw_data:
        print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        print(f"   ë¨¼ì € ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
        print(f"   python -m data.scripts.download_data\n")
        print("="*60 + "\n")
        return

    # ë©”íƒ€ë°ì´í„° ìƒì„±ê¸° ì´ˆê¸°í™”
    meta_gen = MetadataGenerator()
    documents = []
    
    logger.info(f"ì´ {len(raw_data)}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì¤‘...")
    print(f"ğŸ“¦ ì´ {len(raw_data):,}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì¤‘...")

    for idx, item in enumerate(raw_data):
        try:
            # í˜¸í…” ID ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒ ì •ë³´ ìƒì„±
            hotel_id = item.get('hotel_id')
            meta = meta_gen.get_metadata(hotel_id)
            
            # í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
            text = item.get('text', '').lower()
            tags = []
            if 'wifi' in text: tags.append('wifi')
            if 'breakfast' in text: tags.append('breakfast')
            if 'pool' in text: tags.append('pool')
            if 'quiet' in text: tags.append('quiet')
            if 'family' in text: tags.append('family')
            if 'romantic' in text: tags.append('romantic')

            doc = ReviewDocument(
                doc_id=f"review_{idx}",
                hotel_name=meta['name'],      # ê°€ìƒ í˜¸í…” ì´ë¦„
                location=meta['location'],    # ê°€ìƒ ìœ„ì¹˜ (Paris, Seoul ë“±)
                review_text=item.get('text', ''),
                rating=float(item.get('overall', item.get('rating', 0))),
                review_title=item.get('title', ''),
                tags=tags
            )
            documents.append(doc)
            
        except Exception as e:
            continue

    # ì¸ë±ì‹± ì‹¤í–‰ (ë°°ì¹˜ ì²˜ë¦¬)
    print("ğŸ’¾ ElasticSearchì— ì¸ë±ì‹± ì¤‘...")
    rag.index_documents(documents, batch_size=500)
    
    doc_count = rag.es.count(index=rag.index_name)['count']
    logger.success(f"ì¸ë±ì‹± ì™„ë£Œ! ì´ ë¬¸ì„œ ìˆ˜: {doc_count}")
    
    print(f"\nâœ… ì¸ë±ì‹± ì™„ë£Œ!")
    print(f"   ì¸ë±ìŠ¤: {rag.index_name}")
    print(f"   ë¬¸ì„œ ìˆ˜: {doc_count:,}ê°œ")
    print(f"\nğŸ’¡ ì´ì œ 'Paris', 'Seoul' ë“±ìœ¼ë¡œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n")
    print("="*60 + "\n")

if __name__ == "__main__":
    index_data()